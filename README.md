**Spam Mail Prediction system using Machine Learning with python**

I'm going to discuss my project about how to build a spam mail prediction system This is one of an interesting applications of Machine Learning ,as  we came across this in our day to day life.

Let's try to understand how we can use ML effectively in order to predict which are spam mails and which are non spam mails .In a day we receive multiple spam mails . Spam mails are mails that are not true or I can is fake mails .When we use gmail we can see that they classify spam mails and their is a different column or section for spaim mails. So this projects build a similiar system using machine learning that can correctly predict which can be spam mails and which are non spam mails.
Example of spam mail: Last chance to score savings on game-time gear!
The mails which are legit are called Ham mails.
Example of Ham mails: Project Update .

**Steps**

* **Collect Mails Data**, it should contain both spam and ham mails.

* **Data Preprocessing** , it will convert our texts and paragraphs in numbers that can be understand by the computers.

* **Train and Test Split** , need to split data into traning for training the model and testing for evaluate the model.

* **Logistic Regression Model** , feed the training data in this model. And using this model beacuse it is the best when it comes to binary(binary means two,classification between two classes) classification.

* **Trained Logistic regression Model** , because this model is trained with training data andwhen we try to give it a new mail it will classify whether its spam mail or ham mail.


[Spam Mail Dataset](https://www.kaggle.com/datasets/nanditapore/mails-dataset-spam-ham)

[Spam Mail Prediction Notebook](https://www.kaggle.com/code/nanditapore/spam-mail-prediction-system)


First step is uploading the dataset in the environment .I have used Kaggle Notebook you can go through the dataset and you can see a option name "Add Notebook" soo the dataset gets added in the environment second option is that in file you have the option of "Add Input " where you can add your dataset .

#### Importing Dependencies

Starting with our coding we need to Import Dependencies.Dependencies are libraries and the functions that we need in our project .While writing code one must have habbit of writing the text of heading/steps or add a comment. Importing the dependencies, firstly import numpy as np and import pandas as pd this are some of the important libraries that we generally use in ML. Numpy libraries is used in creating numpy arrays and importing it in shortform np soo this is general convention we use. and pandas we used to create data frames as you can see that dataset is in csv format it is difficult to use it , we need a structured tables this is what pandas do it gives Dataframes which helps us to structure our data.

Next import is from sklearn.moel_selection import train_test_split , its an importand library and we need to split our data into training and testing data for that we need this train_test_split function.
Next importing a vectorizer function , from sklearn.feature_extraction.text import TfidfVectorizer  
the purspose of this is that we need to covert the text/mail data into numerical values so the ML model can understand it. In order to convert the text into feature vector (feature vector is numberical values)
Importing Logistic Regression function ,from sklearn.linear_model import Logistic Regression , What to know about  [Logistic Regression Model](https://www.kaggle.com/discussions/general/434926), Using Logistic Regression Model to classify mails into spam mails and ham mails.
Importing Evaulation metrics that is from sklearn.metrics import accuracy_score this accuracy_score function is used to evaluate our model in order to find how well our model is performing and how many good predictions it is making.TThis are all dependencies we require ,after this run the cell.

#### Data Collection and Pre-processing

After importing the dependencies our next step is data collection and preprocessing you can add the text/markdown in your notebook.

Firstly load the data form the csv file , as we have added the input data in notebook ,now we need to load the csv data into pandas dataframe . Pandas library is already imported now need to load the data with the help of pandas.
Add the comment Loading data using pandas or anything according to you soo, it can be understood in future.

Defining a varaible name "data" which is equals to pd.read_csv. pd indicates pandas as we have imported pandas as pd we will use it as pd and this read_csv() function will load the data from csv to pandas dataframe and inside the function "()" in single code need to write the path of the dataset. If using kaggle, on the right hand side of the notebook you can see the data and you can directly copy the path and paste it inside the ' ' single quotes.Then run the cell it will load the dataset in the data variable.Then in the next cell you can write print(data) or just data and run the cell .It will show first 5 records and last 5 records of the dataset, it means the data is correctly loaded.It also shows 2 columns "Category" which says that whether it is a spam mail or ham mail. And "Message" which are mails which are spam and Ham the content of mails.

Thier is a problem in the dataset that it contains lots of missing value , which can be solve by converting them into null strings. We need to deal with missing values because the model will give bias results and it will affect the model's performance.Starting with adding a comment again. We have a variable name data in which we have loaded the data , will take this data and replace the null values(missing values) with the null strings. Define a new variable name "mail_data" which is equals to data.where((pd.notnull(data)),'') , where carries out condition , this condition is that if i have null values replace it will empty string/null string ' ' , then run the cell. Printing the first 5 rows using  ".head()" function. Next need to check how many number of rows or columns present in dataframe in other words number of mails we have in the dataframe.Using ".shape" function it will gives number of rows and columns.It gave (5572, 2) first value is rows and second is columns which means 5572 mails and 2 columns that is category and mails.

#### Label Encoding

Their are 2 labels in the dataset, one label is "spam" and another is "ham", next step is to do is label encoding which means encoding this labels into numberical values .Ham will be replace to 1 and spam will be replace to 0.This will help the model for better performance.So adding a text/markdown "Label Encoding". So the variable mail_data.loc[mail_data['Category'] == 'spam' , 'Category' ]=0. Taking the mail_data ,dataframe and locate values from mail.data check if their is category column if the value is equals to spam if yes then replace it with zero and same with ham write the code and just replace spam with ham and zero with 1 soo it will replace ham with 1 in the dataframe .Run the cell you can check the update by running .head() function.

#### Train and Test Split

Next Spliting the dataset into features and target for example separating the message and the category . Separating this because feeding our model the data and label separately .Feature is nothing but the column that contains the description about the data or characteristics in this case is "Message" column and Target is nothing but the output or the prediction or the classification of the data like Spam or Ham .Creating two variable X and Y , X=mail_daya['Message] and Y=mail_data[;Category] . So X contains the feature or message and Y contains the label or target or category . Try to print X and Y separately for better understanding.

Next Spliting the Data into training and testing it is to be done in every ML model, a set of training data is used for training the model and a set of testing data is used to testing or evluating the model.Adding the text/markdown "Spliting the data into training data and testing data ". Already imported the function train_test_split used to split the data into two sets.For this their a need to mention 4 arrays ,X_train,X_test,Y_train,Y_test its meaning spliting the feature into two sets X_train and X_test . And spliting the target or label into two sets that is Y_train and Y_test.Then write the function train_test_split(X,Y,test_size=0.2,random_state=3 )
X and Y are columsn of the dataset and test_size is 0.2 , it is the amount of data which we want inour test data  which means using 20% data for testing and using 80% data for training the model.X_train and Y_train is the 80% of data and X_test and Y_test is the remaing 20% of the data so need to mention the data points which is required in data that is the test_size and other is random_state , it is not very important but its simple ,given the value 3 in the random_state it is used because whenever we split the data it splites in different ways , first time split the data it will be in a different manner so the next time the data is split in different manner likes mails will go from training data to testiing data . so if we want the data to be split in the same way in all the cases then need to mention the random_state  you can give any value to random_state then it return the same spliting manner .Running the cell then try to print X shape , X_train shape and X_test shape in the next cell to understand the spliting of data.

#### Feature Extraction

Next is to convert the data into numberical value and this part is called Feature Extraction.Already imported Tfidf Vectorizer funciton in order to convert the text into meaningful numberical values that can act as the input  data for Logistic Regression model. Creating a variable name feature_extraction then load the function TfidfVectorizer(min_df = 1, stop_words='english',lowercase=True) so these are three parameters .In the mails of spam their are worfs like "free" , "offer" so tfidf vectorizer will go through all these words in the data and if the word is repeated several times  then it will get some values . Higher the number of times of repeatition of a word higher the score.min_df parameter used in that function is basically  the score of a particular word is lesser than 1 then ignore it and if score is more than 1 then include it .next parameter is stopwords ='english' the words that are repeated like 'is','the','are' etc but these words doesnt make sense or meaning , all these common words are not needed this words are called stopwords and need to ignore them. And the last parameter is lowercase=True which means all the letter s will be converted to lowercase which is better for processing. Next is going to convert the values  X_train and X_test  into numberical values and store it in an array , not to convert the values of Y_train and Y_test because it just conatins 0 and 1 in their value soo creating  X_train_feature  array is eqauls to feature_extraction.fit_transform(X_train)  so this 'feature_extraction' is nothing but the previous variable that is used to convert the text into numberical values  so using it in X_train and fitting the data into the vectorizer to transform the X_train to numberical value. And here in  X_test_feature=feature_extraction.transform(X_test) here it should not be written as fit_transform as it is not required to fit in the vectorizer  beacuse we dont want the model to look at the X_test so it can learn from X_train and the patterns of X_test remains unseen for better evaluation of performance .Next is convert Y_train and Y_test values as integers beacuse Y variable contains the column of Category with values that have converted as 1 and 0 but it is considered as string , data type can be check just print(Y) it is seen dtype as object so it is required to change the values as integers. Lets take Y_train and Y_test such like Y_train = Y_train.astype('int') and same for Y_test and run this . Try to print X_train_feature and it can be seen that the text data is converted in numberical values.

#### Training the Model

Training the Logistic Regression model and it has been already imported so lets load the model . Creating a variable name "model" , so model= LogisticRegression() and run this cell , this will load the logistic regression model in the variable . Now fit the extreme features and Y_train to the LogisticRegression model.Using model so the model requires X-axis and Y-axis  ,X- axis is X_train_feature and Y-axis is Y_train . X_train_feature contains the mail data in numberical form and Y_train 
 contains the label whether it is spam or ham in 1 and 0, both are training data .model.fit(X_train_feature, Y_train), after running this the logistic regression model will be trained.Now if the new mail is given it will tell whether the particular mail is spam or ham. But before that evaluate the model for that it is required to check how many correct predictions model is predicting.

#### Evaluating the Trained Model

Firstly making predictions on training data  , what is need to do here is , as we have used the X_train_feature and Y_train in order to train the model . As our model is trained ,so their a need to provide the X_train_feature to the model ask the model tp predict the Y_train values and then checking how many correct values it is predicting.So need to store all the values predicted by the model as prediction_traindata = model.predict(X_train_feature), for training the model .fit is used and for prediction .predict is used .Now all the values the model predicts will be stored in prediction_traindata. Now camparing the values the model predicted with the actual values.Creating variable name accuracy_traindata = accuracy_score(Y_train,prediction_traindata). Already imported the accuracy_score function so using that function then need to mention two values 'True value' and the 'Predicted value' . 'True value' is nothing by Y_train value and 'Prediction value' is prediction_traindata.then run this and print(accuracy_train) to get the score , the score is 0.9670181736594121 which means it is 96% means out of 100 values you get 96 values correct and this score is good , model working really well. Lets do the same evaluate on testing data , just copy the code and update ,just replace train with test and run it .So the accuracy score of testing data is  0.9659192825112107 which means it is 96.5% which is not very much differnt from the training data. Now the reason of finding the accuracy_score on both training and testing data that in some cases the model can overfit . Overfitting is the problem that occurs in most of the time in machine learning . In such cases what happens is that the model performs very good on training data and give high accuracy score but when it is tried in testing data it gives very less score , it can be said that the model is overtrained .Next is to build a predictive system , that if new mail is given then the train logistic regression model will predict it whether it is spam or ham mail.It will try to predict whether it is 0 or 1 , for example if it predicts 0 means it is spam mail.

#### Building a Predictive System


Now creating an array as input_mail and store the data in the list format . input_mail=["Free ,offer to win a free gift subscribe it soon to avail the offer."] , i have inputed a spam mail in double qoutes as an input it must return 0 because spam is denoted by 0 in our model. But before prediction we have trained the model with numberical data soo for that ,it is reuired to convert this input in numberical , we can use feature_extraction function as it contains the tfidf vectorizer . creating new variable for storing the numberical value of the input as input_data_feature and using feature_extraction.transform(input_mail) beacuse we are predicting . Then for storing the prediction creating variable name prediction  then use model.predict(input_data_feature)
and print predictions, it return 0.Lets add a condition that if the value is 1 return ham and if 0 then return spam. sooo if prediction[0]==1 ,[0] means the first element in the list, its basically the index or the position of the list element .so if the condition is true print("Ham mail") , else print("Spam mail").Second option is user input means their no need to write a mail in code iteself you can ask user to write the mail using user(), this function is used to prompt the user to enter the email text. So  paste the same code just change the input_mail=[input("Enter a mail : ")] then just run the code in the output it will ask for mail then just paste the text and press enter , it will print the output .

#### Conclusion

The Spam Mail Prediction System demonstrates how machine learning can be effectively applied to classify emails as spam or non-spam (ham) with high accuracy. Using the Logistic Regression model, the system achieved an accuracy of approximately 96%, showcasing its capability to correctly predict most cases. Key steps involved data preprocessing, feature extraction using TF-IDF Vectorizer, and training the model with labeled data. The predictive system can classify new emails based on learned patterns, providing a practical solution to spam detection challenges. This project highlights the power of machine learning in automating and improving real-world tasks efficiently.



